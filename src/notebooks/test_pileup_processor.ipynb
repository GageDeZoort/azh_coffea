{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f1b5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from os.path import join\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "from coffea import processor, util\n",
    "from coffea.nanoevents import NanoAODSchema\n",
    "from azh_analysis.processors.pileup_processor import PileupProcessor\n",
    "\n",
    "from azh_analysis.utils.sample import get_fileset, get_sample_info\n",
    "\n",
    "# from azh_analysis.utils.pileup_utils import\n",
    "\n",
    "year=\"2018\"\n",
    "source=\"MC_UL\"\n",
    "verbose=True\n",
    "add_signal=True\n",
    "show_config=False\n",
    "interactive=False\n",
    "\n",
    "# setup logging\n",
    "log_format = \"%(asctime)s %(levelname)s %(message)s\"\n",
    "log_level = logging.DEBUG if verbose else logging.INFO\n",
    "logging.basicConfig(level=log_level, format=log_format)\n",
    "logging.info(\"Initializing\")\n",
    "\n",
    "# relevant parameters\n",
    "csv_indir = \"../samples\"\n",
    "yaml_indir = \"../samples/filesets\"\n",
    "fileset = get_fileset(join(yaml_indir, f\"{source}_{year}.yaml\"))\n",
    "sample_info = get_sample_info(join(csv_indir, f\"{source}_{year}.csv\"))\n",
    "if add_signal:\n",
    "    signal_yaml = f\"signal_UL_{year[:4]}.yaml\"\n",
    "    fileset.update(get_fileset(os.path.join(yaml_indir, signal_yaml)))\n",
    "    signal_csv = join(csv_indir, f\"signal_UL_{year[:4]}.csv\")\n",
    "    sample_info = np.append(sample_info, get_sample_info(signal_csv))\n",
    "\n",
    "\n",
    "fileset = {k: v for k, v in fileset.items()}\n",
    "for f, l in fileset.items():\n",
    "    print(f, len(l), \"\\n\")\n",
    "\n",
    "# start timer, initiate cluster, ship over files\n",
    "tic = time.time()\n",
    "\n",
    "# instantiate processor module\n",
    "processor_instance = PileupProcessor()\n",
    "hists, metrics = processor.run_uproot_job(\n",
    "    fileset,\n",
    "    treename=\"Events\",\n",
    "    processor_instance=processor_instance,\n",
    "    executor=processor.dask_executor,\n",
    "    executor_args=exe_args,\n",
    "    # maxchunks=20,\n",
    "    chunksize=100000,\n",
    ")\n",
    "\n",
    "# measure, report summary statistics\n",
    "elapsed = time.time() - tic\n",
    "logging.info(f\"Output: {hists}\")\n",
    "logging.info(f\"Metrics: {metrics}\")\n",
    "logging.info(f\"Finished in {elapsed:.1f}s\")\n",
    "logging.info(f\"Events/s: {metrics['entries'] / elapsed:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e150423",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
