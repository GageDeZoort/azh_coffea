{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78e73ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import argparse\n",
    "import logging\n",
    "import time\n",
    "from os.path import join\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import uproot\n",
    "from coffea import processor, util\n",
    "from coffea.lumi_tools import LumiMask\n",
    "from coffea.nanoevents import NanoAODSchema, NanoEventsFactory\n",
    "\n",
    "from azh_analysis.processors.analysis_processor import AnalysisProcessor\n",
    "from azh_analysis.utils.btag import get_btag_SFs, get_btag_tables\n",
    "from azh_analysis.utils.corrections import (\n",
    "    dyjets_stitch_weights,\n",
    "    get_electron_ES_weights,\n",
    "    get_electron_ID_weights,\n",
    "    get_electron_trigger_SFs,\n",
    "    get_fake_rates,\n",
    "    get_met_phi_weights,\n",
    "    get_muon_ES_weights,\n",
    "    get_muon_ID_weights,\n",
    "    get_muon_trigger_SFs,\n",
    "    get_pileup_weights,\n",
    "    get_tau_ID_weights,\n",
    ")\n",
    "from azh_analysis.utils.sample import get_fileset, get_nevts_dict, get_sample_info\n",
    "\n",
    "# setup logging\n",
    "log_format = \"%(asctime)s %(levelname)s %(message)s\"\n",
    "logging.basicConfig(level=logging.INFO, format=log_format)\n",
    "logging.info(\"Initializing\")\n",
    "\n",
    "# relevant parameters\n",
    "year, source = '2018', 'signal_UL'\n",
    "\n",
    "# load up golden jsons\n",
    "golden_json_dir = \"../samples/data_certification\"\n",
    "golden_jsons = {\n",
    "    \"2018\": join(golden_json_dir, \"data_cert_2018.json\"),\n",
    "    \"2017\": join(golden_json_dir, \"data_cert_2017.json\"),\n",
    "    \"2016postVFP\": join(golden_json_dir, \"data_cert_2016.json\"),\n",
    "    \"2016preVFP\": join(golden_json_dir, \"data_cert_2016.json\"),\n",
    "}\n",
    "lumi_masks = {year: LumiMask(golden_json) for year, golden_json in golden_jsons.items()}\n",
    "\n",
    "# load up fake rates\n",
    "fr_base = f\"../corrections/fake_rates/UL_{year}\"\n",
    "fake_rates = get_fake_rates(fr_base, year)\n",
    "logging.info(f\"Using fake rates\\n{fr_base}\")\n",
    "\n",
    "# get the met phi weights                                                                                                    \n",
    "met_phi_base = f\"../corrections/met/{year}\"\n",
    "met_phi_file = join(met_phi_base, \"met.json.gz\")\n",
    "met_phi_SFs = get_met_phi_weights(met_phi_file)\n",
    "logging.info(f\"Using met_phi_weights:\\n{met_phi_file}\")\n",
    "\n",
    "# load up electron / muon / tau IDs\n",
    "eID_base = f\"../corrections/electron_ID/UL_{year}\"\n",
    "eID_file = join(\n",
    "    eID_base, f\"Electron_RunUL{year}_IdIso_AZh_IsoLt0p15_IdFall17MVA90noIsov2.root\"\n",
    ")\n",
    "\n",
    "eIDs = get_electron_ID_weights(eID_file)\n",
    "logging.info(f\"Using eID_SFs:\\n{eID_file}\")\n",
    "\n",
    "eES_SFs = get_electron_ES_weights(\"../corrections/electron_ES/\", year)\n",
    "logging.info(f\"Using eES_SFs from corrections/ele_ES/UL_{year}\")\n",
    "\n",
    "mES_SFs = get_muon_ES_weights(\"../corrections/muon_ES/\", year)\n",
    "logging.info(f\"Using mES_SFs from corrections/muon_ES/UL_{year}\")\n",
    "\n",
    "mID_base = f\"../corrections/muon_ID/UL_{year}\"\n",
    "mID_file = join(mID_base, f\"Muon_RunUL{year}_IdIso_AZh_IsoLt0p15_IdLoose.root\")\n",
    "mIDs = get_muon_ID_weights(mID_file)\n",
    "logging.info(f\"Using mID_SFs:\\n{mID_file}\")\n",
    "\n",
    "tID_base = f\"../corrections/tau_ID/UL_{year}\"\n",
    "tID_file = join(tID_base, \"tau.corr.json\")\n",
    "tIDs = get_tau_ID_weights(tID_file)\n",
    "logging.info(f\"Using tID_SFs:\\n{tID_file}\")\n",
    "\n",
    "# load up electron / muon trigger SFs\n",
    "e_trigs = {\n",
    "    \"2016preVFP\": \"Ele25_EtaLt2p1\",\n",
    "    \"2016postVFP\": \"Ele25_EtaLt2p1\",\n",
    "    \"2017\": \"Ele35\",\n",
    "    \"2018\": \"Ele35\",\n",
    "}\n",
    "e_trig_base = f\"../corrections/electron_trigger/UL_{year}\"\n",
    "e_trig_file = join(e_trig_base, f\"Electron_RunUL{year}_{e_trigs[year]}.root\")\n",
    "e_trig_SFs = get_electron_trigger_SFs(e_trig_file)\n",
    "\n",
    "m_trigs = {\n",
    "    \"2016preVFP\": \"IsoMu24orIsoTkMu24\",\n",
    "    \"2016postVFP\": \"IsoMu24orIsoTkMu24\",\n",
    "    \"2017\": \"IsoMu27\",\n",
    "    \"2018\": \"IsoMu27\",\n",
    "}\n",
    "m_trig_base = f\"../corrections/muon_trigger/UL_{year}\"\n",
    "m_trig_file = join(m_trig_base, f\"Muon_RunUL{year}_{m_trigs[year]}.root\")\n",
    "m_trig_SFs = get_muon_trigger_SFs(m_trig_file)\n",
    "\n",
    "# load up btagging tables\n",
    "btag_root = \"../corrections/btag/\"\n",
    "btag_tables = get_btag_tables(btag_root, f\"{year}\", UL=True)\n",
    "btag_SFs = get_btag_SFs(btag_root, f\"{year}\", UL=True)\n",
    "\n",
    "# load up non-signal MC csv / yaml files\n",
    "fset_string = f\"{source}_{year}\"\n",
    "sample_info = get_sample_info(join(\"../samples\", fset_string + \".csv\"))\n",
    "fileset = get_fileset(join(\"../samples/filesets\", fset_string + \".yaml\"))\n",
    "pileup_weights = None\n",
    "if \"MC\" in source or \"signal\" in source:\n",
    "    pileup_weights = get_pileup_weights(\"../corrections/pileup/\", year=year)\n",
    "\n",
    "# only run over root files\n",
    "for sample, files in fileset.items():\n",
    "    good_files = []\n",
    "    for f in files:\n",
    "        if f.split(\".\")[-1] == \"root\":\n",
    "            good_files.append(f)\n",
    "    fileset[sample] = good_files\n",
    "logging.info(f\"running on\\n {fileset.keys()}\")\n",
    "\n",
    "# extract the sum_of_weights from the ntuples\n",
    "nevts_dict, dyjets_weights = None, None\n",
    "\n",
    "if \"MC\" in source:\n",
    "    nevts_dict = get_nevts_dict(fileset, year)\n",
    "    print(\"fileset keys\", fileset.keys())\n",
    "    if f\"DYJetsToLLM-50_{year}\" in fileset.keys():\n",
    "        dyjets_weights = dyjets_stitch_weights(sample_info, nevts_dict, year)\n",
    "        \n",
    "# load up signal MC csv / yaml files\n",
    "fileset = {k: v[:1] for k, v in fileset.items() if \"BBAToZhToLLTauTauM250_2018\" in k}\n",
    "\n",
    "logging.info(f\"Successfully built sum_of_weights dict:\\n {nevts_dict}\")\n",
    "logging.info(f\"Successfully built dyjets stitch weights:\\n {dyjets_weights}\")\n",
    "\n",
    "# start timer, initiate cluster, ship over files\n",
    "tic = time.time()\n",
    "\n",
    "# instantiate processor module\n",
    "proc_instance = AnalysisProcessor(\n",
    "    source=source,\n",
    "    year=year,\n",
    "    sample_info=sample_info,\n",
    "    fileset=fileset,\n",
    "    pileup_weights=pileup_weights,\n",
    "    lumi_masks=lumi_masks,\n",
    "    nevts_dict=nevts_dict,\n",
    "    met_phi_SFs=met_phi_SFs,\n",
    "    eleID_SFs=eIDs,\n",
    "    eleES_SFs=eES_SFs,\n",
    "    muID_SFs=mIDs,\n",
    "    muES_SFs=mES_SFs,\n",
    "    tauID_SFs=tIDs,\n",
    "    e_trig_SFs=e_trig_SFs,\n",
    "    m_trig_SFs=m_trig_SFs,\n",
    "    fake_rates=fake_rates,\n",
    "    dyjets_weights=dyjets_weights,\n",
    "    btag_eff_tables=btag_tables[0],\n",
    "    btag_SFs=btag_SFs,\n",
    "    btag_pt_bins=btag_tables[1],\n",
    "    btag_eta_bins=btag_tables[2],\n",
    "    run_fastmtt=True,\n",
    "    systematic=None,\n",
    "    same_sign=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4137ea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "futures_run = processor.Runner(\n",
    "    executor=processor.FuturesExecutor(compression=None, workers=1),\n",
    "    schema=NanoAODSchema,\n",
    ")\n",
    "\n",
    "out = futures_run(\n",
    "    fileset,\n",
    "    \"Events\",\n",
    "    processor_instance=proc_instance,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0485d322",
   "metadata": {},
   "outputs": [],
   "source": [
    "out[\"dR\"][\"BBAToZhToLLTauTauM250\"][::sum, ::sum, ::sum, ::sum, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b681d442",
   "metadata": {},
   "outputs": [],
   "source": [
    "out[\"met_phi\"][\"BBAToZhToLLTauTauM250\"][::sum, ::sum, ::sum, \"JES_up\", :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c87dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_rate = False\n",
    "proc_instance = AnalysisProcessor(sample_info=sample_info,\n",
    "                                  pileup_tables=pileup_tables,\n",
    "                                  lumi_masks=lumi_masks,\n",
    "                                  nevts_dict=nevts_dict,\n",
    "                                  high_stats=True,\n",
    "                                  eleID_SFs=eIDs, muID_SFs=mIDs, tauID_SFs=tIDs,\n",
    "                                  fake_rates=fake_rates,\n",
    "                                  dyjets_weights=dyjets_weights,\n",
    "                                  e_trig_SFs=e_trig_SFs, m_trig_SFs=m_trig_SFs,\n",
    "                                  btag_eff_tables=btag_eff_tables, btag_SFs=btag_SFs,\n",
    "                                  btag_pt_bins=btag_pt_bins, btag_eta_bins=btag_eta_bins,\n",
    "                                  run_fastmtt=True, fill_hists=True)\n",
    "\n",
    "if fake_rate: \n",
    "    proc_instance = SS4lFakeRateProcessor(sample_info=sample_info,\n",
    "                                          pileup_tables=pileup_tables,\n",
    "                                          mode='tt',\n",
    "                                          nevts_dict=nevts_dict,\n",
    "                                          lumi_masks=lumi_masks,\n",
    "                                          high_stats=True,\n",
    "                                          eleID_SFs=eIDs,\n",
    "                                          muID_SFs=mIDs,\n",
    "                                          tauID_SFs=tIDs,\n",
    "                                          dyjets_weights=dyjets_weights,\n",
    "                                          e_trig_SFs=e_trig_SFs, m_trig_SFs=m_trig_SFs)\n",
    "    to\n",
    "out = processor.run_uproot_job(\n",
    "        fileset ,\n",
    "        treename=\"Events\",\n",
    "        processor_instance=proc_instance,\n",
    "        executor=processor.futures_executor,\n",
    "        executor_args={\"schema\": NanoAODSchema, 'workers': 1},\n",
    "        chunksize=25000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0ec41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hist\n",
    "import numpy as np\n",
    "import awkward as ak\n",
    "\n",
    "base = '/eos/uscms/store/group/lpcsusyhiggs/ntuples/AZh/nAODv9/2018/DY4JetsToLLM-50'\n",
    "file = join(base, 'all_DY4JetsToLLM-50_file001_part_1of3_Electrons.root')\n",
    "events = NanoEventsFactory.from_root(file, schemaclass=NanoAODSchema).events()\n",
    "met = events.MET\n",
    "tau = events.Tau\n",
    "ele = events.Electron\n",
    "mu = events.Muon\n",
    "\n",
    "dataset_axis = hist.axis.StrCategory(name=\"dataset\", label=\"\", categories=[], growth=True)\n",
    "pt_axis = hist.axis.Regular(name=\"pt\", label=r\"$p_T$ [GeV]\", bins=25, start=0, stop=250 )\n",
    "cat_axis = hist.axis.StrCategory(name=\"category\", label=\"\", categories=[], growth=True)\n",
    "dummy_axis = hist.axis.StrCategory(name=\"dummy\", label=\"\",  categories=[], growth=True)\n",
    "output = hist.Hist(dataset_axis, pt_axis, cat_axis, dummy_axis)\n",
    "\n",
    "N = 1000\n",
    "tt = ak.cartesian({'t1': ele[:N], 't2': tau[:N]}, axis=1)\n",
    "ll = ak.combinations(ele[:N], 2, axis=1, fields=['l1', 'l2'])\n",
    "eeet = ak.cartesian({'tt': tt, 'll': ll}, axis=1)\n",
    "eeet = eeet[(ak.argmax(eeet.tt.t1.pt, axis=1, keepdims=True))]\n",
    "eeet = eeet[~ak.is_none(eeet, axis=1)]\n",
    "tt = ak.cartesian({'t1': mu[:N], 't2': tau[:N]}, axis=1)\n",
    "ll = ak.combinations(ele[:N], 2, axis=1, fields=['l1', 'l2'])\n",
    "eemt = ak.cartesian({'tt': tt, 'll': ll}, axis=1)\n",
    "eemt = eemt[(ak.argmax(eemt.tt.t1.pt, axis=1, keepdims=True))]\n",
    "eemt = eemt[~ak.is_none(eemt, axis=1)]\n",
    "eeet['category'] = 'eeet'\n",
    "eemt['category'] = 'eemt'\n",
    "eeet['weights'] = 0.8*np.ones(len(eeet))\n",
    "eemt['weights'] = 0.9*np.ones(len(eemt))\n",
    "cands = {'eeet': eeet, 'eemt': eemt}\n",
    "lltt = ak.concatenate(list(cands.values()), axis=1)\n",
    "\n",
    "t1, t2 = lltt.tt.t1, lltt.tt.t2\n",
    "d_phi = t1.phi - t2.phi\n",
    "d_eta = t1.eta - t2.eta\n",
    "dR = np.sqrt(d_phi**2 + d_eta**2)\n",
    "print(np.histogram(ak.flatten(dR)))\n",
    "\n",
    "lltt = lltt[ak.num(lltt)==1]\n",
    "output.fill(dataset='test', pt=np.array(ak.flatten(lltt.ll.l1.pt)), \n",
    "            category=ak.to_numpy(ak.flatten(lltt.category)),\n",
    "            dummy='nom', weight=ak.to_numpy(ak.flatten(lltt.weights)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380353f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d58ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e3a13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import argparse\n",
    "import logging\n",
    "import time\n",
    "from os.path import join\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import uproot\n",
    "from coffea import processor, util\n",
    "from coffea.lumi_tools import LumiMask\n",
    "from coffea.nanoevents import NanoAODSchema, NanoEventsFactory\n",
    "\n",
    "from coffea import analysis_tools\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "from azh_analysis.selections.preselections import (\n",
    "    append_tight_masks,\n",
    "    build_Z_cand,\n",
    "    check_trigger_path,\n",
    "    closest_to_Z_mass,\n",
    "    count_btags,\n",
    "    dR_ll,\n",
    "    dR_lltt,\n",
    "    filter_MET,\n",
    "    filter_PV,\n",
    "    get_baseline_bjets,\n",
    "    get_baseline_electrons,\n",
    "    get_baseline_jets,\n",
    "    get_baseline_muons,\n",
    "    get_baseline_taus,\n",
    "    get_lepton_count_veto_masks,\n",
    "    get_tt,\n",
    "    highest_LT,\n",
    "    is_prompt,\n",
    "    tight_electrons,\n",
    "    tight_muons,\n",
    "    trigger_filter,\n",
    ")\n",
    "from azh_analysis.utils.parameters import get_categories, get_eras, get_lumis\n",
    "\n",
    "\n",
    "categories = get_categories()\n",
    "cat_to_num = {v: k for k, v in categories.items()}\n",
    "\n",
    "base = '/eos/uscms/store/group/lpcsusyhiggs/ntuples/AZh/nAODv9/2018/DYBJetsToLL_M-50_Zpt-100to200/'\n",
    "files = os.listdir(base)\n",
    "\n",
    "for f in files:\n",
    "    if \".root\" not in f: continue\n",
    "    try:\n",
    "        events = NanoEventsFactory.from_root(\n",
    "            join(base, f), schemaclass=NanoAODSchema\n",
    "        ).events()\n",
    "    except:\n",
    "        continue\n",
    "    print(f)\n",
    "    \n",
    "    # grab baseline leptons, apply energy scale shifts                                   \n",
    "    baseline_e = get_baseline_electrons(events.Electron)\n",
    "    baseline_m = get_baseline_muons(events.Muon)\n",
    "    baseline_t = get_baseline_taus(events.Tau)\n",
    "    MET = events.MET\n",
    "    MET[\"pt\"] = MET.T1_pt\n",
    "    MET[\"phi\"] = MET.T1_phi\n",
    "\n",
    "    # seeds the lepton count veto                                                        \n",
    "    tight_e = baseline_e[tight_electrons(baseline_e)]\n",
    "    tight_m = baseline_m[tight_muons(baseline_m)]\n",
    "\n",
    "    # build ll pairs \n",
    "    candidates={}\n",
    "    for ll_pair in [\"ee\", \"mm\"]:\n",
    "        if (ll_pair[:2] == \"ee\") and (\"_Electrons\" not in f):\n",
    "            continue\n",
    "        if (ll_pair[:2] == \"mm\") and (\"_Muons\" not in f):\n",
    "            continue\n",
    "\n",
    "        l = tight_e if (ll_pair == \"ee\") else tight_m\n",
    "        ll = ak.combinations(l, 2, axis=1, fields=[\"l1\", \"l2\"])\n",
    "        ll = dR_ll(ll)\n",
    "        ll = build_Z_cand(ll)\n",
    "        ll = closest_to_Z_mass(ll)\n",
    "\n",
    "        # apply trigger filter mask                                                      \n",
    "        mask, tpt1, teta1, tpt2, teta2 = trigger_filter(\n",
    "            ll, events.TrigObj, ll_pair\n",
    "        )\n",
    "        mask = mask & check_trigger_path(events.HLT, \"2018\", ll_pair)\n",
    "        ll = ak.fill_none(ll.mask[mask], [], axis=0)\n",
    "        \n",
    "        # build tt pairs, combine to form lltt candidates                                \n",
    "        for cat in [\"eeem\", \"mmem\"]:\n",
    "            if cat[:2] != ll_pair:\n",
    "                continue\n",
    "\n",
    "            # build 4l final state                                                       \n",
    "            tt = get_tt(baseline_e, baseline_m, baseline_t, cat)\n",
    "            lltt = ak.cartesian({\"ll\": ll, \"tt\": tt}, axis=1)\n",
    "            lltt = dR_lltt(lltt, cat)\n",
    "            charge = lltt.tt.t1.charge * lltt.tt.t2.charge\n",
    "            lltt = lltt[charge < 0]\n",
    "            lltt = highest_LT(lltt, cat, apply_LT_cut=False)\n",
    "            mask = np.ones(len(lltt), dtype=bool)\n",
    "            lltt = ak.fill_none(lltt.mask[mask], [], axis=0)\n",
    "            if len(ak.flatten(lltt)) == 0:\n",
    "                continue\n",
    "            print(len(ak.flatten(lltt)))\n",
    "\n",
    "            # determine which legs passed tight selections                               \n",
    "            lltt = append_tight_masks(lltt, cat, relaxed=False)\n",
    "            lltt[\"cat\"] = cat_to_num[cat]\n",
    "            lltt[\"MET\"] = MET\n",
    "\n",
    "            # mask non-prompt and non-tight MC events                                \n",
    "            lltt = lltt[\n",
    "                is_prompt(lltt, cat)\n",
    "            ]\n",
    "            print(\"after prompt\", len(ak.flatten(lltt)))\n",
    "            lltt = lltt [ \n",
    "                lltt.t1_tight & lltt.t2_tight\n",
    "            ]\n",
    "            print(\"after tight\", len(ak.flatten(lltt)))\n",
    "            if len(ak.flatten(lltt)) == 0:\n",
    "                continue\n",
    "                    \n",
    "            # append the candidates                                                      \n",
    "            candidates[cat] = lltt\n",
    "\n",
    "    if len(candidates)==0:\n",
    "        continue \n",
    "        \n",
    "    cands = ak.concatenate(list(candidates.values()), axis=1)\n",
    "    cands, jets, bjets = cands[mask], baseline_j[mask], baseline_b[mask]\n",
    "    cands = ak.flatten(cands)\n",
    "    if len(cands) == 0:\n",
    "        continue\n",
    "\n",
    "    # get lepton count veto masks                                                        \n",
    "    lepton_count_veto_masks = get_lepton_count_veto_masks(\n",
    "        baseline_e[mask], baseline_m[mask], baseline_t[mask]\n",
    "    )\n",
    "    veto_mask = np.zeros(len(cands), dtype=bool)\n",
    "    for cat_str, cat_num in self.cat_to_num.items():\n",
    "        veto_mask = veto_mask | (\n",
    "            lepton_count_veto_masks[cat_str] & (cands.cat == cat_num)\n",
    "        )\n",
    "    cands = cands[veto_mask]\n",
    "    jets = jets[veto_mask]\n",
    "    bjets = bjets[veto_mask]\n",
    "\n",
    "    # count btags                                                                        \n",
    "    cands = count_btags(cands, bjets)\n",
    "    print(len(ak.flatten(cands)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d27033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = '/eos/uscms/store/group/lpcsusyhiggs/ntuples/AZh/nAODv9/2018/DY4JetsToLLM-50'\n",
    "file = join(base, 'all_DY4JetsToLLM-50_file001_part_1of3_Electrons.root')\n",
    "events = NanoEventsFactory.from_root(file, schemaclass=NanoAODSchema).events()\n",
    "#base = '/eos/uscms/store/group/lpcsusyhiggs/ntuples/AZh/nAODv9/2018/SingleMuon_Run2018A'\n",
    "#file = join(base, 'all_SingleMuon_Run2018A_file038_part_2of3_Muons.root')\n",
    "#events = NanoEventsFactory.from_root(file, schemaclass=NanoAODSchema).events()\n",
    "#tag0 = ak.Array(t1.layout.content.project(1)\n",
    "    \n",
    "#l1 = cands.ll.l1\n",
    "#l1_tags = np.asarray(l1.layout.content.tags)\n",
    "#for tag in np.unique(l1_tags):\n",
    "##    tags = l1.layout.content.project(tag)\n",
    " #   ID = tags.content.parameter(\"__record__\")\n",
    "\n",
    "#for cat in ['eemt', 'eeet', 'mmet']:\n",
    "#    l1 = cands.ll.l1[cands.category==cat]\n",
    "#    print(ak.type(l1))\n",
    "#    l1 = l1.layout.content.project(0)\n",
    "#    print(l1)\n",
    "    \n",
    "#cands = ak.concatenate([lltt_eemt, lltt_eeet], axis=1)\n",
    "#print('cands', ak.num(cands))\n",
    "#tags = np.asarray(cands.layout.content.tags)\n",
    "#print(tags)\n",
    "#for tag in np.unique(tags):\n",
    "#    mask = (tags==tag)\n",
    "#    print(np.asarray(cands.layout.content.project(tag)))\n",
    "#    \n",
    "#ele = ak.Array(leptons.layout.content.project(0))\n",
    "#print(ele.dEsigmaUp)\n",
    "\n",
    "ele = events.Electron\n",
    "met = events.MET\n",
    "tau = events.Tau\n",
    "mu = events.Muon\n",
    "jet = events.Jet\n",
    "\n",
    "N=10**6\n",
    "tt = ak.cartesian({'t1': ele[:N], 't2': tau[:N]}, axis=1)\n",
    "ll = ak.combinations(ele[:N], 2, axis=1, fields=['l1', 'l2'])\n",
    "eeet = ak.cartesian({'tt': tt, 'll': ll}, axis=1)\n",
    "eeet = eeet[(ak.argmax(eeet.tt.t1.pt, axis=1, keepdims=True))]\n",
    "tt = ak.cartesian({'t1': mu[:N], 't2': tau[:N]}, axis=1)\n",
    "ll = ak.combinations(ele[:N], 2, axis=1, fields=['l1', 'l2'])\n",
    "eemt = ak.cartesian({'tt': tt, 'll': ll}, axis=1)\n",
    "eemt = eemt[(ak.argmax(eemt.tt.t1.pt, axis=1, keepdims=True))]\n",
    "tt = ak.cartesian({'t1': ele[:N], 't2': tau[:N]}, axis=1)\n",
    "ll = ak.combinations(mu[:N], 2, axis=1, fields=['l1', 'l2'])\n",
    "mmet = ak.cartesian({'tt': tt, 'll': ll}, axis=1)\n",
    "mmet = mmet[(ak.argmax(mmet.tt.t1.pt, axis=1, keepdims=True))]\n",
    "print('eeet', ak.sum(ak.num(eeet)))\n",
    "print('eemt', ak.sum(ak.num(eemt)))\n",
    "print('mmet', ak.sum(ak.num(mmet)))\n",
    "eemt[\"category\"] = 'eemt'\n",
    "eeet[\"category\"] = 'eeet'\n",
    "mmet[\"category\"] = 'mmet'\n",
    "#cands = ak.concatenate([eemt, eeet, mmet], axis=1)\n",
    "cands = eemt\n",
    "cands['met'] = met[:N]\n",
    "cands = cands[~ak.is_none(cands, axis=1)]\n",
    "cands = cands[ak.num(cands)>0]    \n",
    "print(cands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00f154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "def apply_eleES(ele, met, syst='nom'):\n",
    "    if (syst=='nom'):\n",
    "        return ele, met\n",
    "    t0 = time()\n",
    "    pt, eta = ele.pt, ele.eta\n",
    "    phi, mass = ele.phi, ele.mass\n",
    "    in_barrel = (abs(eta) < 1.479)\n",
    "    in_crossover = ((abs(eta) > 1.479) & (abs(eta) < 1.653))\n",
    "    in_endcap = (abs(eta) > 1.653)\n",
    "    barrel_shifts = {'up': 1.03, 'down': 0.97}\n",
    "    crossover_shifts = {'up': 1.04, 'down': 0.96}\n",
    "    endcap_shifts = {'up': 1.05, 'down': 0.95}\n",
    "    weights = (in_barrel * barrel_shifts[syst] +\n",
    "               in_crossover * crossover_shifts[syst] +\n",
    "               in_endcap * endcap_shifts[syst])\n",
    "    ele_p4 = ak.zip({'pt': ele.pt, 'eta': ele.eta,\n",
    "                     'phi': ele.phi, 'mass': ele.mass},\n",
    "                     with_name='PtEtaPhiMLorentzVector')\n",
    "    ele_p4_shift = (weights * ele_p4)\n",
    "    ele_x_diff = (1-weights) * ele.pt * np.cos(ele.phi)\n",
    "    ele_y_diff = (1-weights) * ele.pt * np.sin(ele.phi)\n",
    "    met_x = met.pt * np.cos(met.phi) + ele_x_diff\n",
    "    met_y = met.pt * np.sin(met.phi) + ele_y_diff\n",
    "    met_p4 = ak.zip({'x': met_x, 'y': met_y,\n",
    "                     'z': 0, 't': 0}, with_name='LorentzVector')\n",
    "    met['pt'] = met_p4.pt\n",
    "    met['phi'] = met_p4.phi\n",
    "    return ele_p4_shift, met\n",
    "\n",
    "def apply_eleSmear(ele, met, syst='nom'):\n",
    "    if (syst=='nom'):\n",
    "        return ele, met\n",
    "    shift = ele.dEsigmaUp if (syst=='up') else ele.dEsigmaDown\n",
    "    weights = shift + 1.0\n",
    "    ele_p4 = ak.zip({'pt': ele.pt, 'eta': ele.eta,\n",
    "                     'phi': ele.phi, 'mass': ele.mass},\n",
    "                    with_name='PtEtaPhiMLorentzVector')\n",
    "    ele_p4_shift = (weights * ele_p4)\n",
    "    ele_x_diff = (1-weights) * ele.pt * np.cos(ele.phi)\n",
    "    ele_y_diff = (1-weights) * ele.pt * np.sin(ele.phi)\n",
    "    met_x = met.pt * np.cos(met.phi) + ele_x_diff\n",
    "    met_y = met.pt * np.sin(met.phi) + ele_y_diff\n",
    "    met_p4 = ak.zip({'x': met_x, 'y': met_y,\n",
    "                     'z': 0, 't': 0}, with_name='LorentzVector')\n",
    "    met['pt'] = met_p4.pt\n",
    "    met['phi'] = met_p4.phi\n",
    "    return ele_p4_shift, met_p4\n",
    "\n",
    "print(ele.pt)\n",
    "ele_new, met_new = apply_eleSmear(cands.ll.l1, cands.met, 'up')\n",
    "print(ele_new.pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd578c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[55.8], [71.7], [44.4, 41.4], [68.5, ... 62.7, 20.5], [85.3, 28.4], [99.1, 22.1]]\n",
    "1: 0.03943324089050293\n",
    "2: 0.10126161575317383\n",
    "3: 0.12982583045959473\n",
    "4: 0.17160296440124512\n",
    "[[42.2], [65.1], [53.5], [174], [43.9], ... 48.9], [105, 105], [147], [82.7], [96.1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e50f42",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b64af7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_eleES(ele, met, eleES_shift='nom', eleSmear_shift='nom'):\n",
    "    # decide ES weights by region of the detector\n",
    "    in_barrel = (abs(ele.eta) < 1.479)\n",
    "    in_crossover = ((abs(ele.eta) > 1.479) & (abs(ele.eta) < 1.653))\n",
    "    in_endcap = (abs(ele.eta) > 1.653)\n",
    "    barrel_shifts = {'up': 1.03, 'nom': 1.0, 'down': 0.97}\n",
    "    crossover_shifts = {'up': 1.04, 'nom': 1.0, 'down': 0.96}\n",
    "    endcap_shifts = {'up': 1.05, 'nom': 1.0, 'down': 0.95}\n",
    "    eleES_weights = (in_barrel * barrel_shifts[eleES_shift] +\n",
    "                     in_crossover * crossover_shifts[eleES_shift] +\n",
    "                     in_endcap * endcap_shifts[eleES_shift])\n",
    "\n",
    "    # get smearing weights\n",
    "    if eleSmear_shift=='nom':\n",
    "        shift = 0\n",
    "    else:\n",
    "        shift = ele.dEsigmaUp if (eleSmear_shift=='up') else ele.dEsigmaDown\n",
    "    eleSmear_weights = shift + 1.0\n",
    "\n",
    "    ele_p4 = ak.zip({'pt': ele.pt, 'eta': ele.eta,\n",
    "                     'phi': ele.phi, 'mass': ele.mass},\n",
    "                     with_name='PtEtaPhiMLorentzVector')\n",
    "\n",
    "    # apply weights\n",
    "    weights = eleES_weights * eleSmear_weights\n",
    "    ele_p4_shift = (weights * ele_p4)\n",
    "    ele_x_diff = (1-weights) * ele.pt * np.cos(ele.phi)\n",
    "    ele_y_diff = (1-weights) * ele.pt * np.sin(ele.phi)\n",
    "    diffs = {'x': ele_x_diff, 'y': ele_y_diffs}\n",
    "    return ele_p4_shift, diffs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "met_x = met.pt * np.cos(met.phi) + ele_x_diff\n",
    "    met_y = met.pt * np.sin(met.phi) + ele_y_diff\n",
    "    met_p4 = ak.zip({'x': met_x, 'y': met_y,\n",
    "                     'z': 0, 't': 0}, with_name='LorentzVector')\n",
    "    met['pt'] = met_p4.pt\n",
    "    met['phi'] = met_p4.phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff34d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f097eee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498f9d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import awkward as ak\n",
    "base = '/eos/uscms/store/group/lpcsusyhiggs/ntuples/AZh/nAODv9/2018/BBAToZhToLLTauTauM325'\n",
    "file = join(base, 'all_BBAToZhToLLTauTauM325_file006_part_1of3_Electrons.root')\n",
    "events = NanoEventsFactory.from_root(file, schemaclass=NanoAODSchema).events()\n",
    "ak.concatenate(\n",
    "    [\n",
    "        ak.unflatten(events.run, 1), \n",
    "        ak.unflatten(events.luminosityBlock, 1), \n",
    "        ak.unflatten(events.event, 1),\n",
    "    ], \n",
    "axis=-1).to_numpy()  # event, run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c36b4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "jet[\"pt\"] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07b3a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "from azh_analysis.utils.corrections import get_tau_ID_weights, tau_ID_weight\n",
    "\n",
    "tID_base = f\"../corrections/tau_ID/UL_{year}\"\n",
    "tID_file = join(tID_base, \"tau.corr.json\")\n",
    "tIDs = get_tau_ID_weights(tID_file)\n",
    "tau_ID_weight(taus, tIDs, \"eett\", syst=\"nom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40d3903",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"/uscms_data/d3/jdezoort/AZh_columnar/CMSSW_10_2_9/src/azh_coffea/src/corrections/temp\"\n",
    "for f in os.listdir(base):\n",
    "    vs_e, vs_j = f.split(\"_\")[-2], f.split(\"_\")[-3]\n",
    "    f = uproot.open(join(base, f))\n",
    "    for k in f.keys():\n",
    "        ks = k.split(\"_\"-)\n",
    "        dm, year = ks[0], ks[1]\n",
    "        if \"2016\" in year: \n",
    "            year = year + ks[2]\n",
    "        else:\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ca8e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8e545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "from azh_analysis.utils.corrections import get_tau_ID_weights\n",
    "tID_base = f\"../corrections/tau_ID/UL_{year}\"\n",
    "tID_file = join(tID_base, \"tau.corr.json\")\n",
    "tIDs = get_tau_ID_weights(tID_file)\n",
    "print([k for k in tIDs.keys()])\n",
    "print(tIDs[\"DeepTau2017v2p1VSe\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8dc91f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c482533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azh_analysis.utils.btag import get_btag_SFs, get_btag_tables\n",
    "btag_root = \"../corrections/btag/\"\n",
    "btag_tables = get_btag_tables(btag_root, f\"{year}\", UL=True)\n",
    "btag_SFs = get_btag_SFs(btag_root, f\"{year}\", UL=True)\n",
    "print([k for k in btag_tables[0].keys() if \"ZZ\" in k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3727d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "f = util.load(\"../data_UL_2018_OS_03-10.coffea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5c8504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from coffea import util\n",
    "\n",
    "f = util.load(\"../data_UL_2018_OS_03-10.coffea\")\n",
    "print(f)\n",
    "e = f[\"evtID\"].value\n",
    "l = f[\"lumi_block\"].value\n",
    "ids = np.concatenate([\n",
    "    e.reshape(-1,1), \n",
    "    l.reshape(-1,1),\n",
    "], axis=-1)\n",
    "unique_ids = np.unique(ids, axis=1)\n",
    "len(unique_ids) / len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c397c579",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa6dbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import correctionlib\n",
    "from coffea.lookup_tools import extractor\n",
    "\n",
    "#base = '/eos/uscms/store/group/lpcsusyhiggs/ntuples/AZh/nAODv9/2018/SingleMuon_Run2018A/'\n",
    "#file = join(base, \"all_SingleMuon_Run2018A_file001_part_2of3_Muons.root\")\n",
    "base = '/eos/uscms/store/group/lpcsusyhiggs/ntuples/AZh/nAODv9/2018/DY3JetsToLLM-50'\n",
    "file = join(base, 'all_DY3JetsToLLM-50_file025_part_3of3_Muons.root')\n",
    "events = NanoEventsFactory.from_root(file, schemaclass=NanoAODSchema).events()\n",
    "print(len(events))\n",
    "events = events[events.MET.T1_pt < 6500]\n",
    "print(len(events))\n",
    "met = events.MET\n",
    "print(met.fields)\n",
    "met_pt, met_phi = met.pt, met.phi\n",
    "#npvs, run = events.Pileup.nTrueInt, events.run\n",
    "npvs, run = events.PV.npvs, events.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b7656d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ceval = correctionlib.CorrectionSet.from_file(\"../corrections/met/2018/met.json.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6092c9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "from azh_analysis.utils.corrections import apply_met_phi_SFs\n",
    "\n",
    "met_pt = met.pt[met.pt < 6500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0dc08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_met_phi_SFs(ceval, met, npvs, run, True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cf5340",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = \"2017\"\n",
    "files = {\n",
    "    \"2018\": '/eos/uscms/store/group/lpcsusyhiggs/ntuples/AZh/nAODv9/2018/ZZTo4L/all_ZZTo4L_file003_part_1of3_Muons.root',\n",
    "    \"2017\": '/eos/uscms/store/group/lpcsusyhiggs/ntuples/AZh/nAODv9/2017/ZZTo4LTuneCP5/all_ZZTo4LTuneCP5_file003_part_1of3_Muons.root',\n",
    "    \"2016postVFP\": \"/eos/uscms/store/group/lpcsusyhiggs/ntuples/AZh/nAODv9/2016/ZZTo4LTuneCP5_postVFP/all_ZZTo4LTuneCP5_postFVP_file003_part_1of3_Muons.root\",\n",
    "    \"2016preVFP\": \"/eos/uscms/store/group/lpcsusyhiggs/ntuples/AZh/nAODv9/2016/ZZTo4L_preVFP/all_ZZTo4L_preVFP_file003_part_1of3_Muons.root\",\n",
    "}\n",
    "file = files[year]\n",
    "events = NanoEventsFactory.from_root(file, schemaclass=NanoAODSchema).events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0f2693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import awkward as ak\n",
    "\n",
    "np.unique(events.run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2512a8b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62170168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a5e56a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdeb688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b258fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e18313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "from matplotlib import pyplot as plt\n",
    "from azh_analysis.utils.corrections import get_met_phi_weights, apply_met_phi_SFs\n",
    "\n",
    "# grab met phi weights\n",
    "met_phi_base = f\"../corrections/met/{year}\"\n",
    "met_phi_file = join(met_phi_base, \"met.json.gz\")\n",
    "met_phi_SFs = get_met_phi_weights(met_phi_file)\n",
    "print(met_phi_SFs)\n",
    "\n",
    "met = events.MET\n",
    "met[\"pt\"], met[\"phi\"] = met.T1_pt, met.T1_phi\n",
    "npvs, runs = events.PV.npvsGood, events.run\n",
    "\n",
    "met_phi_before = ak.to_numpy(met.phi)\n",
    "met_pt_before = ak.to_numpy(met.pt)\n",
    "met_after = apply_met_phi_SFs(met_phi_SFs, met, npvs, runs, is_data=False)\n",
    "met_phi_after = ak.to_numpy(met_after.phi)\n",
    "met_pt_after = ak.to_numpy(met_after.pt)\n",
    "\n",
    "print(file)\n",
    "for i in range(20):\n",
    "    print(f\"event {events.event[i]}; phi: {met_phi_before[i]:.6}\\t --> {met_phi_after[i]:.6}\\t pt: {met_pt_before[i]:.6f}\\t --> {met_pt_after[i]:.6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5cf5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=250, figsize=(4,3))\n",
    "plt.hist(met_phi_before, histtype=\"step\", label=\"before\")\n",
    "plt.hist(met_phi_after, histtype=\"step\", label=\"after\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(f\"ZZTo4L {year} file003_1of3_Muons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2587fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1026c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31bd397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa41478",
   "metadata": {},
   "outputs": [],
   "source": [
    "events.MET.T1_pt_unclustEnDown[0:10].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85b2a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "events.MET.T1_pt_unclustEnUp[0:10].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f152d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51c55f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9170e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {\n",
    "    \"2017\": {\n",
    "        \"TT\": [\n",
    "            \"TTToSemiLeptonic\",\n",
    "            \"TTToHadronic\",\n",
    "            \"TTTo2L2Nu\",\n",
    "            \"ttZJets\",\n",
    "            \"TTWJetsToLNu\",\n",
    "        ],\n",
    "        \"ZZ\": [\n",
    "            \"GluGluToContinToZZTo2e2tau\",\n",
    "            \"GluGluToContinToZZTo2mu2tau\",\n",
    "            \"GluGluToContinToZZTo4e\",\n",
    "            \"GluGluToContinToZZTo4mu\",\n",
    "            \"GluGluToContinToZZTo4tau\",\n",
    "            \"ZZTo4L\",\n",
    "            \"ZZTo2Q2Lmllmin4p0\",\n",
    "        ],\n",
    "        \"WZ\": [\n",
    "            \"WZTo2Q2Lmllmin4p0\",\n",
    "            \"WZTo3LNu\",\n",
    "        ],\n",
    "        \"VVV\": [\n",
    "            \"WWW4F\",\n",
    "            \"WWW4F_ext1\",\n",
    "            \"WWZ4F\",\n",
    "            #\"WZZTuneCP5\",\n",
    "            \"WZZ_ext1\",\n",
    "            \"ZZZ\",\n",
    "            #\"ZZZTuneCP5_ext1\",\n",
    "        ],\n",
    "        \"SM-H(125)\": [\n",
    "            \"GluGluHToTauTauM125\",\n",
    "            \"VBFHToTauTauM125\",\n",
    "            \"WminusHToTauTauM125\",\n",
    "            \"WplusHToTauTauM125\",\n",
    "            \"ZHToTauTauM125_ext1\",\n",
    "            \"ttHToTauTauM125\",\n",
    "            \"GluGluHToWWTo2L2NuM-125\",\n",
    "            \"VBFHToWWTo2L2NuM-125\",\n",
    "            \"GluGluZHHToWW\",\n",
    "            \"GluGluHToZZTo4LM125\",\n",
    "            \"HWminusJHToWW\",\n",
    "            \"HWplusJHToWW\",\n",
    "            \"HZJHToWW\",\n",
    "            \"HZJHToWW_ext1\",\n",
    "        ],\n",
    "    },\n",
    "    \"2016postVFP\": {\n",
    "        \"TT\": [\n",
    "            \"TTToSemiLeptonic\",\n",
    "            \"TTToHadronic\",\n",
    "            \"TTTo2L2Nu\",\n",
    "            \"ttZJets\",\n",
    "            \"TTWJetsToLNu\"\n",
    "        ],\n",
    "        \"ZZ\": [\n",
    "            \"GluGluToContinToZZTo2e2tau\",\n",
    "            \"GluGluToContinToZZTo2mu2tau\",\n",
    "            \"GluGluToContinToZZTo4e\",\n",
    "            \"GluGluToContinToZZTo4mu\",\n",
    "            \"GluGluToContinToZZTo4tau\",\n",
    "            \"ZZTo4L\",\n",
    "            \"ZZTo2Q2Lmllmin4p0\"\n",
    "        ],\n",
    "        \"WZ\": [\n",
    "            \"WZTo2Q2L\",\n",
    "            \"WZTo3LNu\",\n",
    "        ],\n",
    "        \"VVV\": [\n",
    "            \"WWW4F\",\n",
    "            \"WWW4F_ext1\",\n",
    "            \"WWZ4F\",\n",
    "            #\"WZZTuneCP5\",\n",
    "            \"WZZ_ext1\",\n",
    "            \"ZZZ\",\n",
    "            #\"ZZZTuneCP5_ext1\",\n",
    "        ],\n",
    "        \"SM-H(125)\": [\n",
    "            \"GluGluHToTauTauM125\",\n",
    "            \"VBFHToTauTauM125\",\n",
    "            \"WminusHToTauTauM125\",\n",
    "            \"WplusHToTauTauM125\",\n",
    "            \"ZHToTauTauM125_ext1\",\n",
    "            \"ttHToTauTauM125\",\n",
    "            \"GluGluHToWWTo2L2NuM-125\",\n",
    "            \"VBFHToWWTo2L2NuM-125\",\n",
    "            \"GluGluZHHToWW\",\n",
    "            \"GluGluHToZZTo4LM125\",\n",
    "            \"HWminusJHToWW\",\n",
    "            \"HWplusJHToWW\",\n",
    "            \"HZJHToWW\",\n",
    "            \"HZJHToWW_ext1\"\n",
    "        ],\n",
    "    },\n",
    "    \"2016preVFP\": {\n",
    "        \"TT\": [\n",
    "            \"TTToSemiLeptonic\",\n",
    "            \"TTToHadronic\",\n",
    "            \"TTTo2L2Nu\",\n",
    "            \"ttZJets\",\n",
    "            \"TTWJetsToLNu\",\n",
    "        ],\n",
    "        \"ZZ\": [\n",
    "            \"GluGluToContinToZZTo2e2tau\",\n",
    "            \"GluGluToContinToZZTo2mu2tau\",\n",
    "            \"GluGluToContinToZZTo4e\",\n",
    "            \"GluGluToContinToZZTo4mu\",\n",
    "            \"GluGluToContinToZZTo4tau\",\n",
    "            \"ZZTo4L\",\n",
    "            \"ZZTo2Q2L\",\n",
    "        ],\n",
    "        \"WZ\": [\n",
    "            \"WZTo2Q2Lmllmin4p0\",\n",
    "            \"WZTo3LNu\",\n",
    "        ],\n",
    "        \"VVV\": [\n",
    "            \"WWW4F\",\n",
    "            \"WWW4F_ext1\",\n",
    "            \"WWZ4F\",\n",
    "            #\"WZZTuneCP5\",\n",
    "            \"WZZ_ext1\",\n",
    "            \"ZZZ\",\n",
    "            #\"ZZZTuneCP5_ext1\",\n",
    "        ],\n",
    "        \"SM-H(125)\": [\n",
    "            \"GluGluHToTauTauM125\",\n",
    "            \"VBFHToTauTauM125\",\n",
    "            \"WminusHToTauTauM125\",\n",
    "            \"WplusHToTauTauM125\",\n",
    "            \"ZHToTauTau_ext1\",\n",
    "            \"ttHToTauTauM125\",\n",
    "            \"GluGluHToWWTo2L2NuM125\",\n",
    "            \"VBFHToWWTo2L2NuM-125\",\n",
    "            \"GluGluZHHToWW\",\n",
    "            \"GluGluHToZZTo4LM125\",\n",
    "            \"HWminusJHToWW\",\n",
    "            \"HWplusJHToWW\",\n",
    "            \"HZJHToWW\",\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc7dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = \"2016preVFP\"\n",
    "ha = util.load(f\"../output_met-phi_before-after/MC_UL_{year}_None_after.coffea\")[\"met_phi\"]\n",
    "hb = util.load(f\"../output_met-phi_before-after/MC_UL_{year}_None_before.coffea\")[\"met_phi\"]\n",
    "\n",
    "ha_grouped, hb_grouped = {}, {}\n",
    "group_year = groups[year]\n",
    "for group, processes in group_year.items():\n",
    "    processes_combined = sum([hb[p][::sum, ::sum, ::sum, ::sum, :] for p in hb.keys() if p in processes])\n",
    "    hb_grouped[group] = processes_combined\n",
    "for group, processes in group_year.items():\n",
    "    processes_combined = sum([ha[p][::sum, ::sum, ::sum, ::sum, :] for p in ha.keys() if p in processes])\n",
    "    ha_grouped[group] = processes_combined\n",
    "\n",
    "hb_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c70b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, dpi=200, figsize=(8,4), sharey=True)\n",
    "for process, hist in hb_grouped.items():\n",
    "    try:\n",
    "        hist.plot1d(ax=axs[0], label=process, stack=True)\n",
    "    except: \n",
    "        print(\"skipping\", process)\n",
    "for process, hist in ha_grouped.items():\n",
    "    try:\n",
    "        hist.plot1d(ax=axs[1], label=process, stack=True)\n",
    "    except: \n",
    "        print(\"skipping\", process)\n",
    "        \n",
    "axs[0].set_xlabel(r\"$\\phi_\\mathrm{MET}$\")\n",
    "axs[0].set_title(f\"{year}: \"+r\"Before $\\phi_\\mathrm{MET}$ Corrections\")\n",
    "axs[1].set_xlabel(r\"$\\phi_\\mathrm{MET}$\")\n",
    "axs[1].set_title(f\"{year}: \"+r\"After $\\phi_\\mathrm{MET}$ Corrections\")\n",
    "plt.legend(loc=\"center right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e25d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a13830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coffea import util\n",
    "import numpy as np\n",
    "data = util.load(\"../data_UL_2018_OS_07-23.coffea\")\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1bf1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.hist(data[\"data_m4l_fine_cons\"].value, bins=np.linspace(0, 2500, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67b9734",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = sum(v for k, v in data[\"m4l_reg\"].items())\n",
    "hist[\"data\", ::sum, ::sum, ::sum, \"cons\", :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5f3476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e768e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "run, evtID, lumi_block, cat, m4l = np.array(data[\"run\"].value), np.array(data[\"evtID\"].value), np.array(data[\"lumi_block\"].value), np.array(data[\"data_cat\"].value), np.array(data[\"data_m4l_fine_cons\"].value)\n",
    "for i in range(len(evtID)):\n",
    "    print(f\"Event {i}\\t Run: {run[i]}\\t evt_id: {evtID[i]}\\t lumi_block: {lumi_block[i]}\\t channel: {cat[i]}\\t m4l: {m4l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ceb817",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
